# ğŸ HackTheTrack Data Setup

## Quick Start (Local Development)

1. **Clone the repo**
```bash
   git clone https://github.com/your-team/hackthetrack.git
   cd hackthetrack
```

2. **Run setup (downloads data automatically)**
```bash
   chmod +x setup.sh
   ./setup.sh
```

3. **Start coding**
```python
   from src.data_processing.race_data_loader import HackTheTrackDataLoader
   loader = HackTheTrackDataLoader()

   # Load data
   telemetry = loader.load('telemetry')
```

## Running Analysis Scripts

All scripts should be run from the project root directory:

```bash
# Data processing
python src/data_processing/merge_and_analyze.py
python src/data_processing/clean_racing_laps.py
python src/data_processing/integrate_weather.py

# Analysis
python src/analysis/advanced_lap_optimization.py

# Dashboards
streamlit run src/dashboards/optimization_dashboard.py --server.port 8501
streamlit run src/dashboards/weather_dashboard.py --server.port 8502

# Or use the convenience script
cd scripts && ./start_dashboards.sh
```

## Google Colab
```python
!pip install gdown
!gdown --folder https://drive.google.com/drive/folders/1IpIK0kjIoD3szP7qdXZU9978PyxFK81O -O data
```

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing/   # Data loading and preprocessing scripts
â”‚   â”œâ”€â”€ analysis/          # Analysis and optimization scripts
â”‚   â””â”€â”€ dashboards/        # Streamlit dashboard applications
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original race datasets
â”‚   â”œâ”€â”€ processed/        # Cleaned and merged data
â”‚   â””â”€â”€ results/          # Analysis outputs and results
â”œâ”€â”€ docs/                 # Documentation and reports
â””â”€â”€ scripts/              # Utility scripts
```

## Data Location

- **Google Drive**: [HackTheTrack Data Folder](https://drive.google.com/drive/folders/1IpIK0kjIoD3szP7qdXZU9978PyxFK81O)
- **Local Cache**: `data/raw/datasets/` (after running setup)
- **Processed Data**: `data/processed/` (generated by processing scripts)

## Available Datasets

Run `loader.load()` to see all available datasets after download.

## Tips

- Use `sample_rows=1000` during development for faster iteration
- Data is cached locally - download only happens once
- Run `loader.info('dataset_name')` to explore any dataset

## Troubleshooting

If download fails:
1. Check internet connection
2. Try downloading manually from the Drive link
3. Place files in `data/raw/` directory
